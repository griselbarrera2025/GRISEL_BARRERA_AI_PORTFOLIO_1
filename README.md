Grisel-Barrera-HCC-AI/
â”œâ”€â”€ README.md
â”œâ”€â”€ NLP-ITAI2373/
â”‚   â”œâ”€â”€ Text-Processing-Project/
â”‚   â”‚   â”œâ”€â”€ preprocessing.ipynb
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ sample_data/
â”‚   â”‚   â””â”€â”€ outputs/
â”‚   â””â”€â”€ Sentiment-And-Emotion-Analysis/
â”‚       â”œâ”€â”€ classifier.py
â”‚       â”œâ”€â”€ README.md
â”‚       â””â”€â”€ results/
â”‚   â”œâ”€â”€ Text-Representation/
â”‚   â”‚   â”œâ”€â”€ tfidf_bow_embeddings.ipynb      # Code for BoW, TF-IDF, Word Embeddings
â”‚   â”‚   â”œâ”€â”€ README.md                       # Based on the Text Representation README I wrote
â”‚   â”‚   â”œâ”€â”€ sample_data/
â”‚   â”‚   â””â”€â”€ outputs/
â”‚   â”œâ”€â”€ Intro-to-Audio-and-Preprocessing/
â”‚   â”‚   â”œâ”€â”€ audio_preprocessing.ipynb       # Code for audio loading, cleaning, MFCCs
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ sample_audio/
â”‚   â”‚   â””â”€â”€ outputs/
â”‚   â”œâ”€â”€ Sentiment-and-Emotion-Analysis/
â”‚   â”‚   â”œâ”€â”€ sentiment_emotion.py            # Combined sentiment + emotion model
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ results/
â”‚   â”œâ”€â”€ Syntax-Parsing-and-Semantic-Analysis/
â”‚   â”‚   â”œâ”€â”€ syntax_semantic.py              # POS tagging, parsing, NER
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ outputs/
â”‚   â””â”€â”€ Part-of-Speech-Tagging/
â”‚       â”œâ”€â”€ classifier.py
â”‚       â”œâ”€â”€ README.md
â”‚       â””â”€â”€ results/
â”œâ”€â”€ Text-Classification-and-NER/
â”‚   â””â”€â”€ SmartSensorSystem/
â”‚       â”œâ”€â”€ iot_model.py
â”‚       â”œâ”€â”€ README.md
â”‚       â””â”€â”€ sensor_data/
â””â”€â”€ Presentation/
    â””â”€â”€ Pf_GriselBarrera_ITAI2376.pdf


# Grisel Barrera â€“ Applied AI & Robotics Portfolio

Welcome to my professional AI portfolio, showcasing hands-on projects completed during the Applied AI and Robotics program at Houston Community College.

## ğŸ‘©â€ğŸ“ About Me
I am currently enrolled in the Applied AI & Robotics program at HCC, where Iâ€™ve developed skills in deep learning, NLP, computer vision, edge AI, and conversational AI systems.

## ğŸ“˜ Courses & Skills
- **Deep Learning (ITAI 2376)** â€“ CNNs, RNNs, GANs, U-Net, optimization, diffusion models
- **Natural Language Processing (ITAI 2373)** â€“ Text preprocessing, sentiment analysis, NER, POS tagging, topic modeling
- **AI at the Edge / IoT (ITAI 3377)** â€“ Embedded AI systems, low-latency models, sensor data integration
- **Conversational AI** â€“ Dialogue systems, intent classification, and LLMs

## ğŸ“Œ Featured Projects
-  [BBC News Classification (NLP)](./NLP-ITAI2373/Text-Processing-Project/)
-  [Emotion Detection from Text](./NLP-ITAI2373/Emotion-Classifier/)
-  [Text_Representation_with_Bag-of-Words, TF-IDF, and Word Embeddings]_(NLP_ITAI2373/TF_IDF)
-  [Smart IoT Sensor Alert System](./AI-at-the-Edge-IoT-ITAI3377/SmartSensorSystem/)
-  [Intro_To_Audio_and Preprocessing]_(/NLP_ITAI2373/Intro_to_Audio_&_Preprocessing/)
-  [Sentiment_and_Emotion_Analysis]_(NLP_ITAI2373/Sentiment_and_Emotion_Analysis/)
-  [Syntax Parsing & Semantic Analysis]_(NLP_ITAI/Syntax_Parsing_&_Semantic_Analysis/)
  
## ğŸ“¬ Contact
ğŸ“§ Email: griselbarrera2016@gmail.com  
ğŸ“ Location: Houston, TX  
ğŸ“ LinkedIn: [linkedin.com/in/GriselBarrera]
# BBC News Classification with NLP

## ğŸ§  Problem Statement
Classify news articles into categories such as business, politics, tech, etc., using NLP techniques on the BBC News dataset.

## ğŸ”§ Approach and Methodology
- Text cleaning (lowercasing, punctuation removal, stopwords, lemmatization)
- TF-IDF vectorization
- Logistic Regression, Random Forest, and Naive Bayes models
- Evaluation with F1 score and confusion matrix

## ğŸ“ˆ Results
- Best model: Logistic Regression with 91.2% accuracy
- Clear separation in confusion matrix between categories like sport and tech
- Balanced performance across all five categories

## âœ… Learning Outcomes
- Mastery of preprocessing and feature extraction pipelines
- Gained hands-on experience with multi-class classification and model evaluation
- Understood limitations of classical models vs. neural approaches

## ğŸ“¦ Requirements
```bash
pip install -r requirements.txt
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords
import string
import nltk

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

def clean_text(text):
    text = text.lower()
    text = ''.join([c for c in text if c not in string.punctuation])
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]
    return " ".join(tokens)

# Load sample data
df = pd.DataFrame({"text": ["This is a sample sentence.", "Another example goes here."]})
df['cleaned'] = df['text'].apply(clean_text)

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df['cleaned'])

print("TF-IDF Matrix Shape:", X.shape)

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Sample emotion-labeled dataset
data = {
    'text': ['I love this!', 'I am so angry', 'This is depressing', 'I am excited!', 'This is sad'],
    'emotion': ['joy', 'anger', 'sadness', 'joy', 'sadness']
}
df = pd.DataFrame(data)

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df['text'])
y = df['emotion']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
clf = LogisticRegression()
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))

# Text Representation with Bag-of-Words, TF-IDF, and Word Embeddings

## ğŸ§  Problem Statement
Explore different ways to convert raw text into numerical features for machine learning models. This project compares the effectiveness of Bag-of-Words (BoW), TF-IDF, and Word Embeddings.

## ğŸ”§ Approach and Methodology
- Preprocessed text using tokenization, stop word removal, and lemmatization.
- Implemented three methods of vectorization:
  - **Bag-of-Words** using `CountVectorizer`
  - **TF-IDF** using `TfidfVectorizer`
  - **Word Embeddings** using pre-trained GloVe vectors

## ğŸ“ˆ Results and Evaluation
- Compared vector shapes and vocabulary size
- Demonstrated how dense vs sparse vectors affect ML models
- TF-IDF captured term importance better than BoW
- Word embeddings captured semantic similarity

## âœ… Learning Outcomes
- Gained practical experience with feature engineering in NLP
- Understood limitations and advantages of different vectorization techniques
- Learned how to integrate external word embedding models

## ğŸ“¦ Requirements
```bash
pip install pandas scikit-learn nltk gensim


---

### ğŸ“ **Syntax Parsing & Semantic Analysis**  
**File:** `README.md`

```markdown
# Syntax Parsing and Semantic Analysis in NLP

## ğŸ§  Problem Statement
Analyze the grammatical structure and meaning of text using syntax trees and semantic role labeling.

## ğŸ”§ Approach and Methodology
- Used **SpaCy** for:
  - Part-of-Speech (POS) Tagging
  - Dependency Parsing
  - Named Entity Recognition
- Explored tree structures and grammatical relations
- Conducted semantic analysis using SpaCy's token attributes:
  - `.lemma_`, `.dep_`, `.head`, `.ent_type_`, etc.

## ğŸ“ˆ Results and Evaluation
- Visualized syntactic trees and dependency arcs
- Identified subject-verb-object relationships
- Extracted entities and their semantic roles

## âœ… Learning Outcomes
- Learned how modern NLP pipelines analyze grammar
- Applied semantic analysis to better understand sentence meaning
- Practiced using token-level NLP tools programmatically

## ğŸ“¦ Requirements
```bash
pip install spacy
python -m spacy download en_core_web_sm





